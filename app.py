import streamlit as st
from dotenv import load_dotenv
load_dotenv()
import os
api_key = os.getenv('OPENAI_API_KEY')
print(f"Loaded API Key: {api_key[:4]}...{api_key[-4:] if api_key else 'None'}")
from basic_rag import BasicBanglaRAG
from datetime import datetime

# Page config minimal
st.set_page_config(page_title="à¦…à¦ªà¦°à¦¿à¦šà¦¿à¦¤à¦¾ - Enhanced Memory", layout="centered")

st.title("ğŸ“š à¦†à¦²à§‹à¦šà§à¦¯ à¦¬à¦¿à¦·à¦¯à¦¼ 'à¦…à¦ªà¦°à¦¿à¦šà¦¿à¦¤à¦¾' - Enhanced Memory")

# Remove API Key input and related logic

# Initialize session state for conversation memory (Short-term memory)
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []

if 'related_topics' not in st.session_state:
    st.session_state.related_topics = set()

# Initialize or reuse RAG system (Long-term memory)
if 'rag_system' not in st.session_state:
    try:
        with st.spinner("ğŸ§  Loading Long-term Memory (Vector Database)..."):
            st.session_state.rag_system = BasicBanglaRAG()
        st.success("âœ… Memory system loaded!")
    except Exception as e:
        st.error(f"RAG initialization failed: {e}")
        st.stop()

# Memory status sidebar
with st.sidebar:
    st.header("ğŸ§  Memory Status")
    
    # Short-term memory
    st.subheader("ğŸ’­ Short-term Memory")
    st.metric("Conversation History", len(st.session_state.conversation_history))
    st.metric("Related Topics", len(st.session_state.related_topics))
    
    # Long-term memory
    st.subheader("ğŸ“š Long-term Memory")
    if st.session_state.rag_system:
        st.metric("Vector Database", f"{len(st.session_state.rag_system.chunks)} chunks")
        st.info("âœ… Knowledge base loaded")
    
    # Show recent topics
    if st.session_state.related_topics:
        st.subheader("ğŸ·ï¸ Discussed Topics")
        for topic in list(st.session_state.related_topics)[-5:]:
            st.write(f"ğŸ“Œ {topic}")
    
    # Clear memory button
    if st.button("ğŸ—‘ï¸ Clear Short-term Memory"):
        st.session_state.conversation_history = []
        st.session_state.related_topics = set()
        st.success("Memory cleared!")

# Input box for question
question = st.text_input(
    "à¦†à¦ªà¦¨à¦¾à¦° à¦ªà§à¦°à¦¶à§à¦¨ à¦²à¦¿à¦–à§à¦¨ (à¦¬à¦¾à¦‚à¦²à¦¾/à¦‡à¦‚à¦°à§‡à¦œà¦¿/à¦¬à§à¦¯à¦¾à¦‚à¦²à¦¿à¦¶)", 
    placeholder="à¦¯à§‡à¦®à¦¨: anupamer boyosh koto? à¦…à¦¥à¦¬à¦¾ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤?"
)

# Search method selection
search_method = st.selectbox(
    "ğŸ” à¦¸à¦¾à¦°à§à¦š à¦ªà¦¦à§à¦§à¦¤à¦¿ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨:",
    ["hybrid", "vector", "keyword"],
    format_func=lambda x: {
        "hybrid": "âš¡ à¦¹à¦¾à¦‡à¦¬à§à¦°à¦¿à¦¡ (à¦¸à§‡à¦°à¦¾ à¦«à¦²à¦¾à¦«à¦² - à¦­à§‡à¦•à§à¦Ÿà¦° + à¦•à§€à¦“à¦¯à¦¼à¦¾à¦°à§à¦¡)",
        "vector": "ğŸ§  à¦¸à¦¿à¦®à¦¾à¦¨à§à¦Ÿà¦¿à¦• à¦¸à¦¾à¦°à§à¦š (à¦…à¦°à§à¦¥ à¦¬à§à¦à§‡ à¦–à§‹à¦à¦œà§‡)",
        "keyword": "ğŸ” à¦•à§€à¦“à¦¯à¦¼à¦¾à¦°à§à¦¡ à¦¸à¦¾à¦°à§à¦š (à¦¶à¦¬à§à¦¦ à¦®à¦¿à¦²)"
    }[x]
)

if st.button("à¦œà¦¿à¦œà§à¦à¦¾à¦¸à¦¾ à¦•à¦°à§à¦¨") and question.strip():
    with st.spinner("ğŸ” à¦‰à¦¤à§à¦¤à¦° à¦–à§à¦à¦œà¦›à§‡ (Short-term + Long-term Memory)..."):
        # Pass conversation history for context-aware responses
        result = st.session_state.rag_system.query(
            question, 
            search_method=search_method,
            conversation_history=st.session_state.conversation_history
        )
    
    st.markdown("### ğŸ’¬ à¦‰à¦¤à§à¦¤à¦°:")
    st.write(result['answer'])
    
    # Add to conversation history (Short-term memory)
    st.session_state.conversation_history.append({
        'timestamp': datetime.now().strftime("%H:%M:%S"),
        'question': question,
        'answer': result['answer'],
        'search_method': search_method
    })
    
    # Extract and add topics to related topics
    question_lower = question.lower()
    topics = []
    if 'anupam' in question_lower or 'à¦…à¦¨à§à¦ªà¦®' in question_lower:
        topics.append('à¦…à¦¨à§à¦ªà¦®')
    if 'kalyani' in question_lower or 'à¦•à¦²à§à¦¯à¦¾à¦£à§€' in question_lower:
        topics.append('à¦•à¦²à§à¦¯à¦¾à¦£à§€')
    if 'mama' in question_lower or 'à¦®à¦¾à¦®à¦¾' in question_lower:
        topics.append('à¦®à¦¾à¦®à¦¾')
    if 'biye' in question_lower or 'à¦¬à¦¿à¦¯à¦¼à§‡' in question_lower or 'marriage' in question_lower:
        topics.append('à¦¬à¦¿à¦¬à¦¾à¦¹')
    if 'shikkha' in question_lower or 'à¦¶à¦¿à¦•à§à¦·à¦¾' in question_lower or 'education' in question_lower:
        topics.append('à¦¶à¦¿à¦•à§à¦·à¦¾')
    
    for topic in topics:
        st.session_state.related_topics.add(topic)
    
    # Show search method used and memory status
    method_names = {
        "hybrid": "âš¡ à¦¹à¦¾à¦‡à¦¬à§à¦°à¦¿à¦¡ à¦¸à¦¾à¦°à§à¦š",
        "vector": "ğŸ§  à¦¸à¦¿à¦®à¦¾à¦¨à§à¦Ÿà¦¿à¦• à¦¸à¦¾à¦°à§à¦š", 
        "keyword": "ğŸ” à¦•à§€à¦“à¦¯à¦¼à¦¾à¦°à§à¦¡ à¦¸à¦¾à¦°à§à¦š"
    }
    
    memory_status = "ğŸ§  Short-term + Long-term Memory" if result.get('used_conversation_memory') else "ğŸ“š Long-term Memory only"
    
    st.info(f"à¦¬à§à¦¯à¦¬à¦¹à§ƒà¦¤ à¦ªà¦¦à§à¦§à¦¤à¦¿: {method_names.get(result.get('search_method', 'hybrid'), 'à¦¹à¦¾à¦‡à¦¬à§à¦°à¦¿à¦¡')} | {memory_status}")
    
    if result.get('relevant_chunks'):
        st.markdown("#### ğŸ“š à¦ªà§à¦°à¦¾à¦¸à¦™à§à¦—à¦¿à¦• à¦¤à¦¥à§à¦¯à¦¸à§‚à¦¤à§à¦° (Long-term Memory):")
        for idx, chunk in enumerate(result['relevant_chunks']):
            # Show similarity score if available
            metadata = chunk.get('metadata', {})
            similarity_info = ""
            if 'similarity_score' in metadata:
                similarity_info = f" (à¦¸à¦¿à¦®à¦¿à¦²à¦¾à¦°à¦¿à¦Ÿà¦¿: {metadata['similarity_score']:.2f})"
            
            st.write(f"{idx+1}. {chunk['text'][:300]}{'...' if len(chunk['text']) > 300 else ''}{similarity_info}")

else:
    st.info("à¦ªà§à¦°à¦¶à§à¦¨ à¦²à¦¿à¦–à§‡ 'à¦œà¦¿à¦œà§à¦à¦¾à¦¸à¦¾ à¦•à¦°à§à¦¨' à¦¬à¦¾à¦Ÿà¦¨à§‡ à¦•à§à¦²à¦¿à¦• à¦•à¦°à§à¦¨à¥¤")
    
    # Sample questions
    st.markdown("### ğŸ¯ à¦¨à¦®à§à¦¨à¦¾ à¦ªà§à¦°à¦¶à§à¦¨:")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼:**")
        st.markdown("â€¢ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤?")
        st.markdown("â€¢ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦šà¦°à¦¿à¦¤à§à¦° à¦•à§‡à¦®à¦¨?")
        st.markdown("â€¢ à¦—à¦²à§à¦ªà§‡à¦° à¦®à§‚à¦² à¦¬à¦¿à¦·à¦¯à¦¼ à¦•à¦¿?")
    
    with col2:
        st.markdown("**à¦¬à§à¦¯à¦¾à¦‚à¦²à¦¿à¦¶à§‡:**")
        st.markdown("â€¢ anupamer boyosh koto?")
        st.markdown("â€¢ kalyani kemon meyer chilo?")
        st.markdown("â€¢ golper main theme ki?")

# Show conversation history (Short-term memory)
if st.session_state.conversation_history:
    st.markdown("---")
    st.markdown("### ğŸ’­ à¦•à¦¥à§‹à¦ªà¦•à¦¥à¦¨à§‡à¦° à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸ (Short-term Memory)")
    
    # Show last 3 conversations
    recent_conversations = st.session_state.conversation_history[-3:]
    
    for i, conv in enumerate(reversed(recent_conversations), 1):
        with st.expander(f"ğŸ• {conv['timestamp']} - {conv['question'][:50]}{'...' if len(conv['question']) > 50 else ''}"):
            st.markdown(f"**à¦ªà§à¦°à¦¶à§à¦¨:** {conv['question']}")
            st.markdown(f"**à¦‰à¦¤à§à¦¤à¦°:** {conv['answer'][:200]}{'...' if len(conv['answer']) > 200 else ''}")
            st.caption(f"à¦ªà¦¦à§à¦§à¦¤à¦¿: {conv['search_method']}")

# Memory explanation
st.markdown("---")
st.markdown("### ğŸ§  Memory System à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾:")
col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    **ğŸ’­ Short-term Memory:**
    - Recent conversation history
    - Discussed topics tracking
    - Session context maintenance
    - Follow-up question support
    """)

with col2:
    st.markdown("""
    **ğŸ“š Long-term Memory:**
    - Vector database (362 chunks)
    - Semantic search capability
    - Knowledge base from PDF
    - Persistent information storage
    """)
